{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e01ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = cv2.imread(\"text_image.png\")\n",
    "binary_img = np.array(255 * (cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY) > 128), dtype=np.uint8)\n",
    "\n",
    "cv2.imshow(\"Input Image\", binary_img)\n",
    "cv2.waitKey(1)\n",
    "\n",
    "img_filtered = size_filter(binary_img, 4000)\n",
    "\n",
    "cv2.imshow(\"Image after Size Filtering\", img_filtered)\n",
    "cv2.waitKey(0)\n",
    "# def posneg_size_filter(img, threshold):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fc9377",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = cv2.imread(\"shape_image.png\")\n",
    "binary_img = np.array(255 * (cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY) > 128), dtype=np.uint8)\n",
    "\n",
    "cv2.imshow(\"Input Image\", binary_img)\n",
    "cv2.waitKey(1)\n",
    "\n",
    "img_filtered = size_filter(binary_img, 4000)\n",
    "\n",
    "cv2.imshow(\"Image after Size Filtering\", img_filtered)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770aab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def label_components_by_flooding(img):\n",
    "\n",
    "    h, w = img.shape\n",
    "    label_img = -(img < 128).astype(np.int)     # Object pixels initialized with label -1, background pixels with 0\n",
    "    current_label = 1                           # Label for first connected component\n",
    "\n",
    "    for row in range(h):\n",
    "        for col in range(w):\n",
    "            if label_img[row, col] < 0:\n",
    "                open_nodes = {(row, col)}       # Set of known unlabeled pixels (possibly with unlabeled neighbors) in the current component \n",
    "                while open_nodes:               # Pop a pixel from the set, label it, and add its neighbors to the set if they are unlabeled object pixels \n",
    "                    (r, c) = open_nodes.pop()\n",
    "                    label_img[r, c] = current_label    \n",
    "                    if r > 0 and label_img[r - 1, c] < 0: \n",
    "                        open_nodes.add((r - 1, c))\n",
    "                    if r < h - 1 and label_img[r + 1, c] < 0: \n",
    "                        open_nodes.add((r + 1, c))\n",
    "                    if c > 0 and label_img[r, c - 1] < 0: \n",
    "                        open_nodes.add((r, c - 1))\n",
    "                    if c < w - 1 and label_img[r, c + 1] < 0: \n",
    "                        open_nodes.add((r, c + 1))\n",
    "                current_label += 1              # No more unlabeled pixels -> move on to next component and increment the label it will get\n",
    "                \n",
    "    return label_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd9b70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_components(img):\n",
    "    h, w = img.shape\n",
    "    label_img = np.zeros((h, w), dtype=np.int)\n",
    "    num_labels = 1\n",
    "    equiv_classes = []\n",
    "    \n",
    "    # # Use the following code whenever you find an object pixel with mismatching upper and left labels \n",
    "    # need_new_class = True\n",
    "    # for cl in equiv_classes:\n",
    "    #     if cl.intersection({upper, left}):\n",
    "    #         cl.update({upper, left})\n",
    "    #         need_new_class = False\n",
    "    #         break\n",
    "    # if need_new_class:\n",
    "    #     equiv_classes.append({upper, left})\n",
    "\n",
    "    # Create a 1-D array for relabeling label_img after the first pass in a single, efficient step\n",
    "    # First: Make sure that all pixels of each component have the same label  \n",
    "    relabel_map = np.array(range(num_labels))\n",
    "    for eq in equiv_classes:\n",
    "        relabel_map[list(eq)] = min(eq)\n",
    "    \n",
    "    # Second: Make sure that there are no gaps in the labeling\n",
    "    # For example, a set of labels [0, 1, 2, 4, 5, 7] would turn into [0, 1, 2, 3, 4, 5]\n",
    "    remaining_labels = np.unique(relabel_map)\n",
    "    relabel_map = np.searchsorted(remaining_labels, relabel_map)\n",
    "\n",
    "    # Finally, relabel label_img and return it\n",
    "    final_label_img = relabel_map[label_img]\n",
    "    return final_label_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7835704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_filter(binary_img, min_size):\n",
    "#     label_matrix = label_components(binary_img)\n",
    "    label_matrix = label_components_by_flooding(binary_img)\n",
    "    _, areas = np.unique(label_matrix, return_counts=True)\n",
    "\n",
    "    # Again, we use a 1-D array for efficient image manipulation. This filter contains one number for each component. \n",
    "    # If the component is smaller than the threshold (or it is the background component 0), its entry in the array is 255.\n",
    "    # Otherwise, its entry is 0. This way, after the mapping, only the above-threshold components will be visible (black).\n",
    "    filter = np.array(255 * (areas < min_size), dtype=np.uint8)\n",
    "    filter[0] = 255\n",
    "    return filter[label_matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302da1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posneg_size_filter(img, threshold):\n",
    "    cv2.imshow(\"Input Image\", img)\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "    imgFilter1 = size_filter(img, threshold)\n",
    "    \n",
    "    cv2.imshow(\"Filter 1 Image\", imgFilter1)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    imgFilter2 = cv2.bitwise_not(imgFilter1)\n",
    "    \n",
    "    cv2.imshow(\"Inv Image\", imgFilter2)\n",
    "    cv2.waitKey(2)\n",
    "    \n",
    "    op = size_filter(imgFilter2, threshold)\n",
    "    \n",
    "    cv2.imshow(\"second last image\", op)\n",
    "    cv2.waitKey(3)\n",
    "    \n",
    "    final = cv2.bitwise_not(op)\n",
    "    \n",
    "    cv2.imshow(\"final Image\", final)\n",
    "    cv2.waitKey(3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e7a058",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputImg = cv2.imread(\"text_image.png\")\n",
    "binaryImg = np.array(255 * (cv2.cvtColor(inputImg, cv2.COLOR_BGR2GRAY) > 128), dtype=np.uint8)\n",
    "img_filtered = posneg_size_filter(binaryImg, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b353b065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def expand_and_shrink(img):\n",
    "    def check_and_convert_4neighbor(pixel_index, img_shape, img, expand):\n",
    "        \"\"\"\n",
    "        Input:pixel_index (int,int): set with pixel coordinate, \n",
    "              img_shape (int, int): set with image height and width respectively,\n",
    "              img (numpy matrix): input image\n",
    "              expand boolean: True for expand else false for shrink\n",
    "        Output:\n",
    "            img (numpy matrix): updated image as per expand/shrink\n",
    "        \"\"\"\n",
    "        four_neighbors = [(pixel_index[0], pixel_index[1]-1), (pixel_index[0], pixel_index[1]+1), (pixel_index[0]-1, pixel_index[1]), (pixel_index[0]+1, pixel_index[1] -1)]\n",
    "        for pixel in four_neighbors:\n",
    "            if pixel[0] < 0 or pixel[1] < 0 or pixel[0] >= img_shape[0] or pixel[1] >= img_shape[1] : # check in 4 neighbour is within image bounds\n",
    "                four_neighbors.remove(pixel)  # if not, remove it from 4 neighbour\n",
    "#         print(\"*******\")\n",
    "#         print(pixel_index)\n",
    "#         print(\"*****\", four_neighbors)\n",
    "        for pixel in four_neighbors:\n",
    "            if expand and img[pixel[0]][pixel[1]] == 255:  # expand --> convert the white pixels to black which are 4 neighbors with black pixel\n",
    "                img[pixel[0]][pixel[1]] = 0\n",
    "            elif not expand and pixel == 0:  #shrink --> convert the black pixels to white which are 4 neighbors with black pixel\n",
    "                img[pixel[0]][pixel[1]] = 255\n",
    "        return img\n",
    "        \n",
    "    h, w = img.shape\n",
    "    \n",
    "    print(h,w)\n",
    "    #expand\n",
    "    for rows_index in range(h):\n",
    "        for cols_index in range(w):\n",
    "            if img[rows_index][cols_index] == 0:\n",
    "                expand_img = check_and_convert_4neighbor((rows_index, cols_index), (h,w), img, True)\n",
    "                \n",
    "    cv2.imshow(\"Expand Image\", expand_img)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    #shrink\n",
    "    for rows_index in range(h):\n",
    "        for cols_index in range(w):\n",
    "            if expand_img[rows_index][cols_index] == 255:\n",
    "                shrink_img = check_and_convert_4neighbor((rows_index, cols_index), (h,w), expand_img, False)\n",
    "    \n",
    "    cv2.imshow(\"Shrink Image\", shrink_img)\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "    return shrink_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d32405",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputImg = cv2.imread(\"text_image.png\")\n",
    "binaryImg = np.array(255 * (cv2.cvtColor(inputImg, cv2.COLOR_BGR2GRAY) > 128), dtype=np.uint8)\n",
    "img_filtered = expand_and_shrink(binaryImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f71fff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_filter(binary_img, min_size):\n",
    "    label_matrix = label_components(binary_img)\n",
    "#     label_matrix = label_components_by_flooding(binary_img)\n",
    "    _, areas = np.unique(label_matrix, return_counts=True)\n",
    "\n",
    "    # Again, we use a 1-D array for efficient image manipulation. This filter contains one number for each component. \n",
    "    # If the component is smaller than the threshold (or it is the background component 0), its entry in the array is 255.\n",
    "    # Otherwise, its entry is 0. This way, after the mapping, only the above-threshold components will be visible (black).\n",
    "    filter = np.array(255 * (areas < min_size), dtype=np.uint8)\n",
    "    filter[0] = 255\n",
    "    return filter[label_matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97167de",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = cv2.imread(\"shape_image.png\")\n",
    "binary_img = np.array(255 * (cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY) > 128), dtype=np.uint8)\n",
    "\n",
    "cv2.imshow(\"Input Image\", binary_img)\n",
    "cv2.waitKey(1)\n",
    "\n",
    "img_filtered = size_filter(binary_img, 4000)\n",
    "\n",
    "cv2.imshow(\"Image after Size Filtering\", img_filtered)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ecb4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
